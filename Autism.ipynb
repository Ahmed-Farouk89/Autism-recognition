{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6225e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=r'E:\\aut'\n",
    "train_dir=os.path.join(dir,'train')\n",
    "test_dir=os.path.join(dir,'test')\n",
    "val_dir=os.path.join(dir,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat))\n",
    "    print('\\33[0m') # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4002d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(train_dir) # class names are the names of the sub directories\n",
    "class_count=len(classes) # determine number of classes\n",
    "batch_size=30 # set training batch size\n",
    "rand_seed=123\n",
    "start_epoch=0 # specify starting epoch\n",
    "epochs=30 # specify the number of epochs to run\n",
    "img_size=224 # use 224 X 224 images compatible with mobilenet model\n",
    "lr=.001 # specify initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296cc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs(dir,b_max):\n",
    "    # dir is the directory containing the samples, b_max is maximum batch size to allow based on your memory capacity\n",
    "    # you only want to go through test and validation set once per epoch this function determines needed batch size ans steps per epoch\n",
    "    length=0\n",
    "    dir_list=os.listdir(dir)\n",
    "    for d in dir_list:\n",
    "        d_path=os.path.join (dir,d)\n",
    "        length=length + len(os.listdir(d_path))\n",
    "    batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=b_max],reverse=True)[0]  \n",
    "    return batch_size,int(length/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91645e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batch_size, valid_steps=get_bs(val_dir, 100)\n",
    "test_batch_size, test_steps=get_bs(test_dir,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a13a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input, horizontal_flip=True).flow_from_directory(\n",
    "        train_dir,  target_size=(img_size, img_size), batch_size=batch_size, seed=rand_seed, class_mode='categorical', color_mode='rgb')\n",
    "\n",
    "valid_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input) .flow_from_directory(val_dir, \n",
    "                    target_size=(img_size, img_size), batch_size=valid_batch_size,\n",
    "                    class_mode='categorical',color_mode='rgb', shuffle=False)\n",
    "test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(test_dir,\n",
    "                    target_size=(img_size, img_size), batch_size=test_batch_size,\n",
    "                    class_mode='categorical',color_mode='rgb', shuffle=False )\n",
    "test_file_names=test_gen.filenames  # save list of test files names to be used later\n",
    "test_labels=test_gen.labels # save test labels to be used later\n",
    "\n",
    "\n",
    "val_file_names=valid_gen.filenames  # save list of test files names to be used later\n",
    "val_labels=valid_gen.labels # save test labels to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels=next(train_gen)\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    image=(images[i]+1 )/2\n",
    "    plt.imshow(image)\n",
    "    index=int(labels[i][1])\n",
    "    plt.title(classes[index], color='black')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be56bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = tf.keras.applications.densenet.DenseNet201( include_top=False, input_shape=(img_size, img_size,3), pooling='max', weights='imagenet') \n",
    "_model.trainable=False\n",
    "x=_model.layers[-1].output # this is the last layer in the mobilenet model the global max pooling layer\n",
    "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x=Dense(128, activation='relu')(x)\n",
    "x=Dropout(rate=.4, seed = 123)(x)\n",
    "predictions=Dense (len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=_model.input, outputs=predictions)    \n",
    "for layer in model.layers:\n",
    "    layer.trainable=True\n",
    "model.compile(Adamax(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb231263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRA(keras.callbacks.Callback):\n",
    "    best_weights=model.get_weights() # set a class vaiable so weights can be loaded after training is completed\n",
    "    def __init__(self, patience=2, threshold=.95, factor=.5):\n",
    "        super(LRA, self).__init__()\n",
    "        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n",
    "        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
    "        self.factor=factor # factor by which to reduce the learning rate\n",
    "        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n",
    "        self.highest_tracc=0.0 # set highest training accuracy to 0\n",
    "        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n",
    "        self.count=0\n",
    "        msg='\\n Starting Training - Initializing Custom Callback'\n",
    "        print_in_color (msg, (244, 252, 3), (55,65,80))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        acc=logs.get('accuracy')  # get training accuracy        \n",
    "        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n",
    "            if acc>self.highest_tracc: # training accuracy improved in the epoch\n",
    "                msg= f'\\n training accuracy improved from  {self.highest_tracc:7.2f} to {acc:7.2f} learning rate held at {lr:9.6f}'\n",
    "                print_in_color(msg, (0,255,0), (55,65,80))\n",
    "                self.highest_tracc=acc # set new highest training accuracy\n",
    "                LRA.best_weights=model.get_weights() # traing accuracy improved so save the weights\n",
    "                count=0 # set count to 0 since training accuracy improved\n",
    "                if v_loss<self.lowest_vloss:\n",
    "                    self.lowest_vloss=v_loss                    \n",
    "            else:  # training accuracy did not improve check if this has happened for patience number of epochs if so adjust learning rate\n",
    "                if self.count>=self.patience -1:\n",
    "                    self.lr= lr* self.factor # adjust the learning by factor\n",
    "                    tf.keras.backend.set_value(model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                    self.count=0 # reset the count to 0\n",
    "                    if v_loss<self.lowest_vloss:\n",
    "                        self.lowest_vloss=v_loss\n",
    "                    msg=f'\\nfor epoch {epoch +1} training accuracy did not improve for {self.patience } consecutive epochs, learning rate adjusted to {lr:9.6f}'\n",
    "                    print_in_color(msg, (255,0,0), (55,65,80))\n",
    "                else:\n",
    "                    self.count=self.count +1\n",
    "                    msg=f'\\nfor  epoch {epoch +1} training accuracy did not improve, patience count incremented to {self.count}'\n",
    "                    print_in_color(msg, (255,255,0), (55,65,80))\n",
    "        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n",
    "            if v_loss< self.lowest_vloss: # check if the validation loss improved\n",
    "                msg=f'\\n for epoch {epoch+1} validation loss improved from  {self.lowest_vloss:7.4f} to {v_loss:7.4}, saving best weights'\n",
    "                print_in_color(msg, (0,255,0), (55,65,80))\n",
    "                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n",
    "                LRA.best_weights=model.get_weights() # validation loss improved so save the weights\n",
    "                self.count=0 # reset count since validation loss improved               \n",
    "            else: # validation loss did not improve\n",
    "                if self.count>=self.patience-1:\n",
    "                    self.lr=self.lr * self.factor\n",
    "                    msg=f' \\nfor epoch {epoch+1} validation loss failed to improve for {self.patience} consecutive epochs, learning rate adjusted to {self.lr:9.6f}'\n",
    "                    self.count=0 # reset counter\n",
    "                    print_in_color(msg, (255,0,0), (55,65,80))\n",
    "                    tf.keras.backend.set_value(model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                else: \n",
    "                    self.count =self.count +1 # increment the count\n",
    "                    msg=f' \\nfor epoch {epoch+1} validation loss did not improve patience count incremented to {self.count}'\n",
    "                    print_in_color(msg, (255,255,0), (55,65,80))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data):\n",
    "    #Plot the training and validation data\n",
    "    history=tr_data.history\n",
    "    tacc=results.history['accuracy']\n",
    "    tloss=results.history['loss']\n",
    "    vacc=results.history['val_accuracy']\n",
    "    vloss=results.history['val_loss']\n",
    "    Epoch_count=len(tloss)\n",
    "    Epochs=[]\n",
    "    for i in range (0,Epoch_count):\n",
    "        Epochs.append(i+1)\n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    val_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1,val_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fad9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[LRA()]\n",
    "results=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=test_gen,\n",
    "               validation_steps=test_steps,  shuffle=True,  initial_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99174f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(LRA.best_weights)\n",
    "acc_val=model.evaluate( valid_gen, batch_size=valid_batch_size, verbose=1, steps=valid_steps)[1]* 100\n",
    "msg_val=f'accuracy on the test set is {acc_val:5.2f} %'\n",
    "print_in_color(msg_val, (0,255,0),(55,65,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='E:\\\\'\n",
    "save_loc=os.path.join(out_dir, str(acc_val)[:str(acc_val).rfind('.')+3] + '.h5')\n",
    "model.save(save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0335da8",
   "metadata": {},
   "source": [
    " From here the real-live testing applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "model = tf.keras.models.load_model(\"E:\\\\87.00.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db43415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs(dir,b_max):\n",
    "    # dir is the directory containing the samples, b_max is maximum batch size to allow based on your memory capacity\n",
    "    # you only want to go through test and validation set once per epoch this function determines needed batch size ans steps per epoch\n",
    "    length=0\n",
    "    dir_list=os.listdir(dir)\n",
    "    for d in dir_list:\n",
    "        d_path=os.path.join (dir,d)\n",
    "        length=length + len(os.listdir(d_path))\n",
    "    batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=b_max],reverse=True)[0]  \n",
    "    return batch_size,int(length/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=r'E:\\aut'\n",
    "test2_dir=os.path.join(dir,'test2')\n",
    "test2_batch_size, test2_steps=get_bs(test2_dir,100)\n",
    "classes=os.listdir(test2_dir) # class names are the names of the sub directories\n",
    "class_count=len(classes) # determine number of classes\n",
    "batch_size=30 # set training batch size\n",
    "rand_seed=123\n",
    "start_epoch=0 # specify starting epoch\n",
    "epochs=30 # specify the number of epochs to run\n",
    "img_size=224 # use 224 X 224 images compatible with mobilenet model\n",
    "lr=.001 # specify initial learning rate\n",
    "test2_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(test2_dir,\n",
    "                    target_size=(img_size, img_size), batch_size=test2_batch_size,\n",
    "                    class_mode='categorical',color_mode='rgb', shuffle=False )\n",
    "test2_file_names=test2_gen.filenames  # save list of test files names to be used later\n",
    "test2_labels=test2_gen.labels # save test labels to be used later\n",
    "Y_pred = model.predict(test2_gen)\n",
    "\n",
    "y_pred=[]\n",
    "print(Y_pred)\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i][0]<0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "print (y_pred)\n",
    "print(test2_gen.class_indices)\n",
    "x,y=next(test2_gen)\n",
    "print(x[0].shape)\n",
    "plt.imshow(x[0,:,:,:])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1c4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
